{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Gesture Prediction Using CNN\n",
    "\n",
    "This project aims to build a Convolutional Neural Network (CNN) to predict hand gestures. The following code snippets demonstrate the process of importing necessary libraries, data preprocessing, model creation, training, and evaluation.\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "First, we need to import the necessary libraries for data manipulation, visualization, and building the CNN model.\n",
    "\n",
    "- `numpy` and `pandas` for data manipulation\n",
    "- `matplotlib` and `seaborn` for data visualization\n",
    "- `keras` for building the CNN model\n",
    "- `tensorflow.keras.preprocessing.image.ImageDataGenerator` for augmenting the image data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "Load the datasets for training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train datasets\n",
    "\n",
    "train_df = pd.read_csv(\"Dataset/sign_mnist_train.csv\")\n",
    "\n",
    "# Test datasets\n",
    "\n",
    "test_df = pd.read_csv(\"Dataset/sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Training Dataset\n",
    "\n",
    "To understand the structure of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Test Dataset\n",
    "\n",
    "To understand the structure of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics of the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating Labels and Features\n",
    "\n",
    "In this step, we separate the labels and features in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train_df['label']\n",
    "train_label.head()\n",
    "trainset=train_df.drop(['label'],axis=1)\n",
    "trainset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping the Training Data\n",
    "The feature set `trainset` is converted to a numpy array and reshaped to fit the input shape required by the CNN model.\n",
    "then print the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset.values\n",
    "X_train = trainset.values.reshape(-1,28,28,1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the Test Data\n",
    "Similarly to the training data, we prepare the test data by separating the labels and features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label=test_df['label']\n",
    "X_test=test_df.drop(['label'],axis=1)\n",
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the Labels\n",
    "Before training the model, we need to encode the labels using one-hot encoding. This step is necessary because our CNN model will output probabilities for each class, and one-hot encoding transforms the labels into a format suitable for this.\n",
    "- We use `LabelBinarizer` from `sklearn.preprocessing` to perform one-hot encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb=LabelBinarizer()\n",
    "y_train=lb.fit_transform(train_label)\n",
    "y_test=lb.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the Encoded Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping the Test Data\n",
    "Similar to the training data, we reshape the test data to fit the input shape required by the CNN model.\n",
    "\n",
    "- The `values` attribute is used to convert `X_test` into a numpy array.\n",
    "- The `reshape` method reshapes the data into a 4D tensor with dimensions (-1, 28, 28, 1), where:\n",
    "  - `-1` indicates that the number of samples will be inferred automatically.\n",
    "  - `28, 28` are the dimensions of the images.\n",
    "  - `1` indicates that the images are grayscale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of Data Arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation for Training Data\n",
    "\n",
    "To improve the robustness and generalization of our model, we apply data augmentation techniques to the training data using `ImageDataGenerator` from `tensorflow.keras.preprocessing.image`.\n",
    "\n",
    "- `rescale`: Rescales the pixel values of images to the range [0, 1].\n",
    "- `rotation_range`, `height_shift_range`, `width_shift_range`, `shear_range`, `zoom_range`, `horizontal_flip`, `fill_mode`: Various parameters for augmenting the images by rotating, shifting, shearing, zooming, flipping horizontally, and filling in new pixels.\n",
    "\n",
    "These techniques help the model generalize better by exposing it to a wider variety of augmented images during training.\n",
    "\n",
    "Additionally, we normalize the pixel values of `X_test` by dividing by 255 to ensure consistency in data preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range = 0,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  shear_range=0,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview of Dataset\n",
    "The following code snippet generates a visual preview of sample images from the training dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axe=plt.subplots(2,2)\n",
    "fig.suptitle('Preview of dataset')\n",
    "axe[0,0].imshow(X_train[0].reshape(28,28),cmap='gray')\n",
    "axe[0,0].set_title('label: 3  letter: C')\n",
    "axe[0,1].imshow(X_train[1].reshape(28,28),cmap='gray')\n",
    "axe[0,1].set_title('label: 6  letter: F')\n",
    "axe[1,0].imshow(X_train[2].reshape(28,28),cmap='gray')\n",
    "axe[1,0].set_title('label: 2  letter: B')\n",
    "axe[1,1].imshow(X_train[4].reshape(28,28),cmap='gray')\n",
    "axe[1,1].set_title('label: 13  letter: M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Convolutional Neural Network (CNN) Model\n",
    "\n",
    "We define a Sequential model for the CNN architecture to classify hand gestures.\n",
    "\n",
    "- The model begins with a `Conv2D` layer with 128 filters, each of size 5x5, using ReLU activation, and input shape (28, 28, 1).\n",
    "- A `MaxPool2D` layer follows with a pool size of 3x3 and strides of 2, using 'same' padding.\n",
    "- The next `Conv2D` layer has 64 filters of size 2x2, also using ReLU activation and 'same' padding.\n",
    "- Another `MaxPool2D` layer follows with a pool size of 2x2 and strides of 2.\n",
    "- Finally, a third `Conv2D` layer has 32 filters of size 2x2, ReLU activation, and 'same' padding.\n",
    "- Another `MaxPool2D` layer with a pool size of 2x2 and strides of 2 follows.\n",
    "\n",
    "The `Flatten()` layer is added to convert the 2D feature maps into a 1D vector, which will be fed into the fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(128,kernel_size=(5,5),\n",
    "                 strides=1,padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(3,3),strides=2,padding='same'))\n",
    "model.add(Conv2D(64,kernel_size=(2,2),\n",
    "                strides=1,activation='relu',padding='same'))\n",
    "model.add(MaxPool2D((2,2),2,padding='same'))\n",
    "model.add(Conv2D(32,kernel_size=(2,2),\n",
    "                strides=1,activation='relu',padding='same'))\n",
    "model.add(MaxPool2D((2,2),2,padding='same'))\n",
    "          \n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Fully Connected Layers\n",
    "\n",
    "We add fully connected (Dense) layers to the CNN model for classification.\n",
    "\n",
    "- `Dense(units=512, activation='relu')`: Adds a dense layer with 512 units and ReLU activation function.\n",
    "- `Dropout(rate=0.25)`: Applies dropout regularization with a rate of 25% to prevent overfitting.\n",
    "- `Dense(units=24, activation='softmax')`: Adds the output layer with 24 units (corresponding to the number of classes) and softmax activation function for multi-class classification.\n",
    "\n",
    "The `summary()` method prints a summary of the model architecture, displaying the number of parameters and the output shape at each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512,activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=24,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model\n",
    "\n",
    "Before training, we compile the CNN model with the specified optimizer, loss function, and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "We train the compiled CNN model using the `fit` method.\n",
    "\n",
    "- `train_datagen.flow(X_train, y_train, batch_size=200)`: Generates batches of augmented data from `X_train` and `y_train` using the previously defined `train_datagen`.\n",
    "  - `batch_size=200`: Specifies the batch size for training.\n",
    "\n",
    "- `epochs=35`: Number of epochs (iterations over the entire dataset) to train the model.\n",
    "\n",
    "- `validation_data=(X_test, y_test)`: Optional validation data to evaluate the model performance after each epoch on data not used for training.\n",
    "\n",
    "- `shuffle=1`: Shuffles the training data before each epoch.\n",
    "\n",
    "The `fit` method trains the model on the training data and validates it on the validation data if provided, while also tracking metrics such as loss and accuracy over epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(train_datagen.flow(X_train,y_train,batch_size=200),\n",
    "         epochs = 35,\n",
    "          validation_data=(X_test,y_test),\n",
    "          shuffle=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "We evaluate the trained CNN model using the `evaluate` method.\n",
    "\n",
    "- `x=X_test, y=y_test`: Specifies the test data (`X_test` and `y_test`) to evaluate the model's performance.\n",
    "\n",
    "The `evaluate` method returns a tuple containing the loss value and accuracy score achieved by the model on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ls,acc)=model.evaluate(x=X_test,y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Model Accuracy\n",
    "\n",
    "To present the model's accuracy in a human-readable format, we print it as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MODEL ACCURACY = {}%'.format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Training and Validation Metrics\n",
    "\n",
    "We visualize the training and validation metrics (accuracy and loss) over epochs using matplotlib.\n",
    "\n",
    "- The first subplot (`plt.subplot(1, 2, 1)`) plots the model accuracy (`accuracy` and `val_accuracy`) over epochs.\n",
    "  - `history.history['accuracy']`: Training accuracy values stored during model training.\n",
    "  - `history.history['val_accuracy']`: Validation accuracy values stored during model training.\n",
    "\n",
    "- The second subplot (`plt.subplot(1, 2, 2)`) plots the model loss (`loss` and `val_loss`) over epochs.\n",
    "  - `history.history['loss']`: Training loss values stored during model training.\n",
    "  - `history.history['val_loss']`: Validation loss values stored during model training.\n",
    "\n",
    "Each plot includes labels, titles, and legends to enhance readability. The `plt.tight_layout()` ensures that subplots are neatly arranged, and `plt.show()` displays the plots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Confusion Matrix\n",
    "\n",
    "We generate and display the confusion matrix to evaluate the model's performance in predicting hand gestures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred_classes):\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=lb.classes_, yticklabels=lb.classes_)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Labels to Letters\n",
    "\n",
    "The `getLetter` function maps numeric labels to corresponding letters based on a predefined dictionary (`classLabels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to match label to letter\n",
    "\n",
    "def getLetter(result):\n",
    "  classLabels ={\n",
    "      0:'A',\n",
    "      1:'B',\n",
    "      2:'C',\n",
    "      3:'D',\n",
    "      4:'E',\n",
    "      5:'F',\n",
    "      6:'G',\n",
    "      7:'H',\n",
    "      8:'I',\n",
    "      9:'K',\n",
    "      10:'L',\n",
    "      11:'M',\n",
    "      12:'N',\n",
    "      13:'O',\n",
    "      14:'P',\n",
    "      15:'Q',\n",
    "      16:'R',\n",
    "      17:'S',\n",
    "      18:'T',\n",
    "      19:'U',\n",
    "      20:'V',\n",
    "      21:'W',\n",
    "      22:'X',\n",
    "      23:'Y',\n",
    "      24:'Z'}\n",
    "\n",
    "  try:\n",
    "    res = int(result)\n",
    "    return classLabels[res]\n",
    "  except:\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "We generate and print the classification report to evaluate the precision, recall, F1-score, and support for each class.\n",
    "\n",
    "- `classification_report(y_true, y_pred_classes, target_names=[getLetter(i) for i in range(len(lb.classes_))])`: Computes and prints a detailed classification report using `classification_report` from `sklearn.metrics`.\n",
    "  - `y_true`: True class labels for each sample in `y_test`.\n",
    "  - `y_pred_classes`: Predicted class labels (indices of maximum probabilities) for each sample in `X_test`.\n",
    "  - `target_names`: Optional parameter specifying the display names for each class, obtained using `getLetter(i)` function for each class index.\n",
    "\n",
    "## Distribution of Labels in Training Set\n",
    "\n",
    "We visualize the distribution of labels in the training set using a bar plot.\n",
    "\n",
    "- `sns.countplot(x=train_label)`: Generates a count plot of `train_label` using `countplot` from `seaborn`.\n",
    "- `ax.set_xticklabels(class_labels)`: Sets the x-axis tick labels to actual letter representations obtained from `getLetter(i)` function for each class index.\n",
    "- Annotations (`ax.annotate`) are added on top of each bar to display the count of samples for each class.\n",
    "\n",
    "The plot provides insights into the distribution of different hand gesture labels in the training dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=[getLetter(i) for i in range(len(lb.classes_))]))\n",
    "\n",
    "# Distribution of Labels in Training Set\n",
    "import seaborn as sns\n",
    "\n",
    "# Class labels mapping\n",
    "class_labels = [getLetter(i) for i in range(len(lb.classes_))]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.countplot(x=train_label)\n",
    "\n",
    "# Set labels for x-axis with actual letter representation\n",
    "ax.set_xticklabels(class_labels)\n",
    "\n",
    "# Add count labels on top of each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', fontsize=9, color='black', xytext=(0, 5),\n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.title('Distribution of Labels in Training Set')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/code/sayakdasgupta/sign-language-classification-cnn-99-40-accuracy/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time Hand Gesture Recognition Using OpenCV and Trained Model\n",
    "\n",
    "This code snippet demonstrates real-time hand gesture recognition using a webcam (assuming `model` and `getLetter` functions are defined beforehand).\n",
    "\n",
    "- `cap = cv2.VideoCapture(0)`: Initializes the webcam capture using OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Assuming model and getLetter are defined before this code\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Define region of interest (ROI)\n",
    "    roi = frame[100:400, 320:620]\n",
    "    cv2.imshow('roi', roi)\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    cv2.imshow('roi scaled and gray', roi)\n",
    "    copy = frame.copy()\n",
    "    cv2.rectangle(copy, (320, 100), (620, 400), (0, 255, 0), 5)\n",
    "\n",
    "    roi = roi.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    # Use predict method instead of predict_classes\n",
    "    predictions = model.predict(roi)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "    result = str(predicted_class)\n",
    "    cv2.putText(copy, getLetter(result), (320, 90), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', copy)\n",
    "\n",
    "    if cv2.waitKey(1) == 13:  # Press 'Enter' key to break the loop\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
